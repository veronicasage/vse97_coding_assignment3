{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I assessed the fairness of Google's Perspective API with regard to gender discrimination. I hypothesize that the model will be less likely to mark anti-female derogatory comments as toxic than anti-male comments.To test this, I wrote 3 pairs of comments, each consisting of two comments which were identical except for gendered language, which was female in one comment and male in the other."
      ],
      "metadata": {
        "id": "UB1-Isp8tA6b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qrN67CmsOaD",
        "outputId": "8343af16-5eb9-46de-c942-05319f09952d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I love cats': {'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 21, 'score': {'value': 0.8988238, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8988238, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}, \"These girls don't know anything\": {'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 21, 'score': {'value': 0.8988238, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8988238, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}, \"These boys don't know anything\": {'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 21, 'score': {'value': 0.8988238, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8988238, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}, 'This woman is so stupid': {'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 21, 'score': {'value': 0.8988238, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8988238, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}, 'This man is so stupid': {'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 21, 'score': {'value': 0.8988238, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8988238, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}}\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient import discovery\n",
        "import json\n",
        "\n",
        "API_KEY = 'AIzaSyBRMNlbdy9J-M5aZ-cc2xQD7UAFlH9dC-E'\n",
        "\n",
        "client = discovery.build(\n",
        "  \"commentanalyzer\",\n",
        "  \"v1alpha1\",\n",
        "  developerKey=API_KEY,\n",
        "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "  static_discovery=False,\n",
        ")\n",
        "\n",
        "comments = [\"These girls don't know anything\", \"These boys don't know anything\", \"This woman is so stupid\", \"This man is so stupid\", \"I hate it when girls act like this\", \"I hate it when boys act like this\"]\n",
        "responses = []\n",
        "\n",
        "for comment in comments:\n",
        "  analyze_request = {\n",
        "    'comment': { 'text': comment },\n",
        "    'requestedAttributes': {'TOXICITY': {}}\n",
        "  }\n",
        "  response = client.comments().analyze(body=analyze_request).execute()\n",
        "  responses.append(response)\n",
        "\n",
        "res = {}\n",
        "for comment in comments:\n",
        "    for responses in responses:\n",
        "        res[comment] = response\n",
        "        #comments.remove(comment)\n",
        "        #break\n",
        "\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments 1 and 2 both received a score of .89; comments 3 and 4 both received a score of .92; comments 5 and 6 both received a score of .84. The fact that the gendered language in the comments didn't affect their toxicity score indicates that the Perspective API is not biased with regard to gender. I think it's likely that the developers of the model kept gender bias in mind while building it took steps to minimize it, possibly intentionally training it to ignore gendered language. The world and the internet at large do discriminate based on gender, so I think that the model's fairness probably took some thought and intentionally on Google's part.\n",
        "\n",
        "While I was doing this testing, I was surprised by how high the toxicity score was for the comments I used. I wouldn't be fazed to see those comments on a Youtube video, and I probably wouldn't even think twice about it. This impressed on me just how toxic the internet can be and how normalized it's become.\n",
        "\n",
        "Although the model isn't biased with regards to gender, I think it's likely that there are some hidden biases. It's relatively easy to train it to ignore things like gendered or racial language, but much harder to make it fair with regards to more complex linguistic elements like syntax and comment length. Therefore, I think it's entirely possible that the model is less accurate on shorter comments, comments that use less common words, or linguistically complex comments."
      ],
      "metadata": {
        "id": "8L5m5_Zzu8oQ"
      }
    }
  ]
}